{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------Read Excel Data---------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "features = pd.read_excel('Book9.xlsx')\n",
    "features.isnull().values.any()\n",
    "# Descriptive statistics for each column\n",
    "features.describe(include='all')\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['GI_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------Prepare Data----------------------------\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('GI_code', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "# Convert to numpy array\n",
    "features = np.array(features)\n",
    "#Clear Other Cancer Patients Instances\n",
    "features_clear=np.delete(features,np.where(labels>11)[0],axis=0)\n",
    "labels_clear=np.delete(labels,np.where(labels>11)[0],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.Counter'>\n",
      "Training Features Shape: (34444, 19)\n",
      "Training Labels Shape: (34444,) Counts: Counter({10: 34255, 11: 189})\n",
      "Testing Features Shape: (14762, 19)\n",
      "Testing Labels Shape: (14762,) Counts: Counter({10: 14664, 11: 98})\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------Normalize Data------------------------------\n",
    "from sklearn.preprocessing import MinMaxScaler,Normalizer,RobustScaler,StandardScaler\n",
    "scaler_minmax = MinMaxScaler()\n",
    "scaler_norm = Normalizer()\n",
    "scaler_robust = RobustScaler()\n",
    "scaler_standard = StandardScaler()\n",
    "minmax_features=np.zeros_like(features_clear)\n",
    "norm_features=np.zeros_like(features_clear)\n",
    "robust_features=np.zeros_like(features_clear)\n",
    "standard_features=np.zeros_like(features_clear)\n",
    "for i in range(features.shape[1]):\n",
    "    minmax_features[:, i] = scaler_minmax.fit_transform(features_clear[:, i].reshape(-1, 1))[:, 0]\n",
    "    norm_features[:, i] = scaler_norm.fit_transform(features_clear[:, i].reshape(-1, 1))[:, 0]\n",
    "    robust_features[:, i] = scaler_robust.fit_transform(features_clear[:, i].reshape(-1, 1))[:, 0]\n",
    "    standard_features[:, i] = scaler_standard.fit_transform(features_clear[:, i].reshape(-1, 1))[:, 0]\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(minmax_features, labels_clear, test_size = 0.3, random_state = 37)\n",
    "from collections import Counter\n",
    "print(Counter)\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape,'Counts:',Counter(train_labels))\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape,'Counts:',Counter(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298246</td>\n",
       "      <td>0.026426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.308070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.026426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206791</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.038595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.212158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.021790</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.221140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.210157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49201</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.037552</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.370857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49202</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.130737</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49203</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.035698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.237813</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49204</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.042321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.322924</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49205</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.054242</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.194608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49206 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2    3    4    5    6         7    8    9      10  \\\n",
       "0      0.0  0.298246  0.026426  1.0  1.0  1.0  1.0  0.000000  1.0  1.0  0.250   \n",
       "1      1.0  0.245614  0.026426  1.0  0.0  0.0  1.0  0.000000  1.0  1.0  0.250   \n",
       "2      1.0  0.210526  0.038595  1.0  1.0  1.0  1.0  0.000000  1.0  1.0  0.125   \n",
       "3      1.0  0.263158  0.021790  1.0  0.0  0.0  1.0  0.000000  1.0  1.0  0.250   \n",
       "4      1.0  0.228070  0.221140  1.0  1.0  1.0  1.0  0.000000  1.0  1.0  0.250   \n",
       "...    ...       ...       ...  ...  ...  ...  ...       ...  ...  ...    ...   \n",
       "49201  0.0  0.333333  0.037552  1.0  1.0  1.0  1.0  0.333333  1.0  1.0  0.125   \n",
       "49202  0.0  0.631579  0.130737  1.0  0.0  0.0  1.0  0.000000  1.0  1.0  0.125   \n",
       "49203  1.0  0.421053  0.035698  1.0  1.0  1.0  1.0  0.000000  1.0  1.0  0.250   \n",
       "49204  1.0  0.350877  0.042321  1.0  1.0  1.0  1.0  0.000000  1.0  1.0  0.250   \n",
       "49205  1.0  0.508772  0.054242  1.0  1.0  1.0  1.0  0.000000  1.0  1.0  0.125   \n",
       "\n",
       "        11        12   13   14        15   16   17   18  \n",
       "0      1.0  0.666667  0.0  1.0  0.308070  1.0  1.0  1.0  \n",
       "1      1.0  0.333333  0.0  0.0  0.206791  1.0  1.0  0.0  \n",
       "2      0.5  0.666667  0.0  1.0  0.212158  1.0  0.0  0.0  \n",
       "3      0.0  1.000000  0.0  0.0  0.377626  1.0  0.0  0.0  \n",
       "4      0.5  0.333333  0.0  1.0  0.210157  1.0  0.0  0.0  \n",
       "...    ...       ...  ...  ...       ...  ...  ...  ...  \n",
       "49201  0.0  0.666667  0.0  1.0  0.370857  1.0  0.0  1.0  \n",
       "49202  0.0  0.666667  0.0  0.0  0.297348  1.0  1.0  0.0  \n",
       "49203  0.0  0.333333  0.0  1.0  0.237813  1.0  0.0  0.0  \n",
       "49204  0.5  0.666667  0.0  1.0  0.322924  1.0  0.0  0.0  \n",
       "49205  0.5  0.333333  0.0  1.0  0.194608  1.0  0.0  0.0  \n",
       "\n",
       "[49206 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(minmax_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Loss 'log_loss' not supported. ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m=\u001b[39mGradientBoostingClassifier(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[0;32m     20\u001b[0m                                 n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20000\u001b[39m, subsample\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m     21\u001b[0m                                 criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     22\u001b[0m                                 min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_weight_fraction_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m     23\u001b[0m                                 verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Train the model on training data\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:525\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    523\u001b[0m     X_val \u001b[38;5;241m=\u001b[39m y_val \u001b[38;5;241m=\u001b[39m sample_weight_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 525\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_initialized():\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;66;03m# init state\u001b[39;00m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_state()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:282\u001b[0m, in \u001b[0;36mBaseGradientBoosting._check_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate must be greater than 0 but was \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate\n\u001b[0;32m    276\u001b[0m     )\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_SUPPORTED_LOSS\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _gb_losses\u001b[38;5;241m.\u001b[39mLOSS_FUNCTIONS\n\u001b[0;32m    281\u001b[0m ):\n\u001b[1;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0:s}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not supported. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss))\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# TODO: Remove in v1.2\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mls\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Loss 'log_loss' not supported. "
     ]
    }
   ],
   "source": [
    "#----------------------------------------Data Augmantation and Resampling------\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "over_svm = SVMSMOTE(sampling_strategy=0.5)#,k_neighbors=5)\n",
    "over_border = SVMSMOTE(sampling_strategy=0.5)#,k_neighbors=5)\n",
    "over_smote = SMOTE(sampling_strategy=0.1)#,k_neighbors=5)\n",
    "over_adasyn = SVMSMOTE(sampling_strategy=0.2)#,k_neighbors=5)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('o', over_smote), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X, y = pipeline.fit_resample(minmax_features, labels_clear)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "\n",
    "model=GradientBoostingClassifier(loss='log_loss', learning_rate=0.01,\n",
    "                                n_estimators=20000, subsample=1.0,\n",
    "                                criterion='squared_error', min_samples_split=2,\n",
    "                                min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "                                verbose=1)\n",
    "# Train the model on training data\n",
    "history=model.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.train_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter)\n",
    "print('Training Features Shape:', X.shape)\n",
    "print('Training Labels Shape:', y.shape,'Counts:',Counter(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "pred_labels=model.predict(X)\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\\n\",metrics.confusion_matrix(y, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.train_score_)\n",
    "plt.title('Train loss ')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "pred_labels=model.predict(test_features)\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\\n\",metrics.confusion_matrix(test_labels, pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy score is : \",metrics.accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------Feature Importance----------------------\n",
    "# Get numerical feature importances\n",
    "importances = list(model.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
    "#----------------------------------------Plot Feature Importance----------------------\n",
    "# Import matplotlib for plotting and use magic command for Jupyter Notebooks\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib inline\n",
    "# Set the style\n",
    "plt.figure(figsize=(20,2))\n",
    "plt.style.use('fivethirtyeight')\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
